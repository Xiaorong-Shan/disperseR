---
title: "Vignette - Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this vignette you will see how to use the `disperser` package. We will walk you through an example step by step. In this vignette we are using functions that will automatically download the needed data for you to run your analysis for the United States. We also provide other vignettes that show you how we processed the data used in case you want to run the analysis for a different country or using different data sources. 

## The step up 

We start by importing the packages that we will use in the analysis. Make sure you have them installed. The functions in `disperser` are based on the `data.table` package for faster computation, but this vignette contains many functions from the `tidyverse` family to illustrate another syntax. 

```{r, message = FALSE, warning = FALSE}
library(disperseR) # our package
library(ncdf4)
library(data.table)
library(tidyverse)
library(kableExtra)
library(parallel)
library(sf)
library(viridis)
library(ggplot2)
library(scales)
library(maps)
library(ggsn)
```

The `create_dirs` function creates a project folder with all the necessary subfolders that we need. Begin by setting up your project with this function. Provide the path to where you would like your project to live in the `location` argument. By default, this function will create a main directory on your desktop. It will also assign paths to string variables in your environment. 

The set up is the following:

* `main`: The main folder where the project will be located. 
  + `input`: the input that we need for calculations. 
    * `zcta_500k`: ZCTA (A Zip Code Tabulation Area) shapefiles
    * `hpbl`: Monthly global planetary boundary layer files.
    * `meteo`: (reanalysis) meteorology files
  + `output`
    * `hysplit`: hyspdisp output (one file for each emissions event)
    * `ziplink`: files containing ZIP code linkages
    * `rdata`: RData files containing HyADS source-receptor matrices
    * `exp`: exposure per zipcode data 
  + `process`: temporary files that are created when the model is running and then deleted


```{r}
create_dirs()
```

## The inputs 

The next step is to get the data necessary for the analysis.  Let's start by loading data sets that are provided inside `disperser`.

### The crosswalk

ZIP code linkage procedure requires a ZCTA-to-ZIP code crosswalk file. ZCTAs are not exact geographic matches to ZIP codes, and multiple groups compile and maintain Crosswalk files. We used the Crosswalk mainted by UDS Mapper and preprocessed it also including information about the population size. While not necessary for the HYSPLIT model or processing of its outputs, population-weighted exposure metrics allow for direct comparisons between power plants. If you would like to know more details about how this crosswalk was prepared, we have attached a vignette that explains it. 

Let's load the crosswalk file. 

```{r}
crosswalk <- disperseR::crosswalk
crosswalk 
```

The disper package also includes monthly power plant emissions, load, and heat input data, accessible using the following command:

### The monthly powerplant emissions

```{r}
PP.units.monthly1995_2017 <- disperseR::PP.units.monthly1995_2017
PP.units.monthly1995_2017
```

### The shape files

Equally important is the ZCTA shapefile. Using the `get_data()` function and specifing the `data` argument to `"zctashapefile"` you can download and preprocess the file from the [US census website](http://www2.census.gov/geo/tiger/GENZ2017/shp/cb_2017_us_zcta510_500k.zip) automatically. If the file already exists in the correct folder, this function will preprocess it and load it into your R environment. 

```{r}
zcta <- get_data(data = "zctashapefile")
zcta
```

### Monthly mean boundary layer heights 

Another input that we need are the monthly mean boundary layer heights. Again, using the `get_data()` function and specifing the `data` argument to `"pblheight"`. If you need more information about how this data has been preprocessed just check the special vignette that is available with the package. We used the data that you can find by clicking on this link [ESRL website](https://www.esrl.noaa.gov/psd/repository/entry/get/hpbl.mon.mean.nc?entryid=synth%3Ae570c8f9-ec09-4e89-93b4-babd5651e7a9%3AL05BUlIvTW9udGhsaWVzL21vbm9sZXZlbC9ocGJsLm1vbi5tZWFuLm5j). 

```{r}
pblheight <- get_data(data = "pblheight")
pblheight
```

### The units data 

Now, we need to select the power plants that we will run. In this case, we'll use the three units in 2005 with the greatest SOx emissions. This package contains annual emissions and stack height data from [EPA's Air Markets Program Data](https://ampd.epa.gov/ampd/) and the [Energy Information Agency] (https://www.eia.gov/electricity/data/eia860/) for 2005, 2006, 2011 and 2012.


```{r}
unitsrun <- disperseR::units2005 %>% dplyr::select(.,-c(V1)) %>% dplyr::top_n(5, SOx)
```


